
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <title>Yangqing Jia</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Le styles -->
    <link href="assets/css/bootstrap.min.css" rel="stylesheet">
    <link href="assets/css/bootstrap-responsive.min.css" rel="stylesheet">
    <link href="assets/css/yangqing.css" rel="stylesheet">

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
    <script src="assets/js/html5shiv.js"></script>
    <![endif]-->
  </head>

  <body>

    <div class="container">
      <div class="row">
        <div class="span3 bs-docs-sidebar">
          <!-- We use a fancy nav bar if there is enough space -->
          <hr class="hidden-phone"/>
          <ul class="nav nav-list bs-docs-sidenav hidden-phone">
            <li><a href="index.html"><i class="icon-play"></i>Home</a></li>
            <li><a href="index.html#research"><i class="icon-play"></i>Research</a></li>
            <li><a href="index.html#publications"><i class="icon-play"></i>Publications</a></li>
            <li><a href="index.html#software"><i class="icon-play"></i>Software</a></li>
            <li><a href="index.html#teaching"><i class="icon-play"></i>Teaching</a></li>
            <li><a href="assets/pdf/CV.pdf"><i class="icon-play"></i>CV</a></li>
          </ul>
          <hr class="hidden-phone"/>
          <div class="text-center hidden-phone">
            <img src="assets/img/Yangqing.png" alt="photo" class="logo-image"/>
          </div>
          <!-- Otherwise, we simply use a flat list of links -->
          <div class="visible-phone">
            <a href="index.html"><i class="icon-play"></i>Home</a>
            <a href="index.html#research"><i class="icon-play"></i>Research</a>
            <a href="index.html#publications"><i class="icon-play"></i>Publications</a>
            <a href="index.html#software"><i class="icon-play"></i>Software</a>
            <a href="index.html#teaching"><i class="icon-play"></i>Teaching</a>
            <a href="assets/pdf/CV.pdf"><i class="icon-play"></i>CV</a>
          </div>
        </div>
        <div class="span9">
          <h3>
	Yangqing Jia
	(º÷—Ô«Â<a href="http://en.wikipedia.org/wiki/Chinese_character"><i class="icon-question-sign"></i></a>)
</h3>
<h5>
<a href="mailto:me@daggerfs.com">me@daggerfs.com</a>
</h5>
<!-- Do I want to show a pic on the phone screen?
<div class="text-center visible-phone">
	<img src="assets/img/Yangqing.png" alt="photo" width="150px"/>
</div>
-->
<a class="visible-phone pull-left" href="#">
  <img class="media-object" src="assets/img/Yangqing.png" width="96px" style="margin: 0px 10px" />
</a>
<p>
I am currently a research scientist at Facebook, where I lead the effort of building a general, large-scale platform for the many AI applications at Facebook. Previously, I was a research scientist at Google Brain where I worked on computer vision, deep learning and TensorFlow.
</p>
<p>
I obtained my Ph.D. in Computer Science at UC Berkeley, advised by Prof. <a href="http://eecs.berkeley.edu/~trevor/">Trevor Darrell</a>. During my graduate study I've worked/interned at the National University of Singapore, Microsoft Research Asia, NEC Labs America, and Google Research. I obtained my bachelor and master degrees from Tsinghua University, China.</p>
<p>
I am the author of <a href="http://caffe.berkeleyvision.org/">Caffe</a>, which is now a <a href="http://bvlc.eecs.berkeley.edu/">BVLC</a> maintained, open-source deep learning framework. I've worked on the <a href="https://www.tensorflow.org/">TensorFlow</a> project at Google Brain.
</p>

<p>
	I do have a <a href="http://www.linkedin.com/pub/yangqing-jia/b/37/a67">LinkedIn profile</a>.

</p>



<!--
 *** Research ***
-->
<h3>
	<a name='research'></a> Research 
</h3>
<p>
My current research topics include:
    <ul>
        <li> Learning better structures for image feature extraction.
        <li> Explaining human generalization behavior with visually grounded cogscience models.
        <li> Making large-scale vision feasible and affordable.
    </ul>
</p>




<!--
 *** Publications ***
-->
<p> (Most recent publications to be added) </p>
<h3>
	<a name='publications'></a> Recent Publications 
</h3>
<p>
    Links to: <a href="publications.html">[Full List]</a>
	<a href="http://scholar.google.com/citations?user=mu5Y2rYAAAAJ&hl=en" target="_blank">[Google Scholar]</a>
    <!--<a href="projects.html"> [Unpublished Projects]</a>-->
</p>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/decaf-features.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition</strong><br />
      J Donahue, Y Jia, O Vinyals, J Hoffman, N Zhang, E Tzeng, T Darrell. arXiv preprint.<br />
      <a href="http://arxiv.org/abs/1310.1531">[ArXiv Link]</a>
      <a href="http://decaf.berkeleyvision.org/">[Live Demo]</a>
      <a href="https://github.com/UCB-ICSI-Vision-Group/decaf-release/">[Software]</a>
      <a href="http://www.eecs.berkeley.edu/~jiayq/decaf_pretrained/">[Pretrained ImageNet Model]</a>
    </p>
    <p class="abstract-text">
    We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be re-purposed to novel generic tasks. We also released the software and pre-trained network to do large-scale image classification.
    </p> 
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/mrFrog.jpg" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Visual Concept Learning: Combining Machine Vision and Bayesian Generalization on Concept Hierarchies</strong><br />
      Y Jia, J Abbott, J Austerweil, T Griffiths, T Darrell. NIPS 2013.
      <a href="#">[PDF coming soon]</a>
    </p>
    <p class="abstract-text">
    It is marvelous that human can learn concept from a small number of examples, a challenge many existing machine vision systems fail to do. We present a system combining computer vision and cogscience to model such human behavior, as well as a new dataset for future experientation on human concept learning.
    </p> 
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/iccv13_ta.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Latent Task Adaptation with Large-scale Hierarchies</strong><br />
      Y Jia, T Darrell. ICCV 2013.
      <a href="#">[PDF coming soon]</a>
    </p>
    <p class="abstract-text">
    How do we adapt our ImageNet classifiers to accurately classify just giraffes and bears on a zoo trip? We proposed a novel framework that benefits from big training data and adaptively adjusts itself for subcategory test scenarios. 
    </p> 
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/iccv13_sa.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Category Independent Object-level Saliency Detection</strong><br />
      Y Jia, M Han. ICCV 2013.
      <a href="#">[PDF coming soon]</a>
    </p>
    <p class="abstract-text">
    We proposed a simple yet efficient approach to combine high-level object models and low-level appearance information to perform saliency detection that identifies foreground objects.
    </p> 
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/icml13.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>On Compact Codes for Spatially Pooled Features</strong><br />
      Y Jia, O Vinyals, T Darrell. ICML 2013.
      <a href="http://jmlr.org/proceedings/papers/v28/jia13.pdf">[PDF]</a>
      <a href="assets/pdf/icml13_poster.pdf">[poster]</a>
      <a href=http://arxiv.org/abs/1301.5348>[ICLR workshop version]</a>
    </p>
    <p class="abstract-text">
      We analyzed the connection between codebook size and accuracy with the Nystrom sampling theory, and showed how this leads to better pooling-aware codebook learning methods.
    </p> 
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/nips12.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Learning with Recursive Perceptual Representations</strong><br />
      O Vinyals, Y Jia, L Deng, T Darrell. NIPS 2012.
      <a href="assets/pdf/nips12_rsvm.pdf">[PDF]</a>
      <a href="assets/pdf/nips12_rsvm_poster.pdf">[Poster]</a>
    </p>
    <p class="abstract-text">
      We proposed R2SVM, an efficient algorithm to recursively learn deep nonlinear models by stacking linear SVMs with random projections.
    </p> 
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/cvpr12.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Beyond Spatial Pyramids: Receptive Field Learning for Pooled Image Features</strong><br />
      Y Jia, C Huang, T Darrell. CVPR 2012.
      <a href="assets/pdf/cvpr12_pooling.pdf">[PDF]</a>
      <a href="assets/pdf/cvpr12_pooling_slides.pdf">[Slides]</a>
      <a href="assets/pdf/cvpr12_pooling_poster.pdf">[Poster]</a>
    </p>
    <p class="abstract-text">
      We showed the suboptimality of spatial pyramids in feature pooling, and proposed an efficient way to learn task-dependent receptive fields for better pooled features.
    </p>
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/uai12.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Factorized Multi-modal Topic Model</strong><br />
      S Virtanen, Y Jia, A Klami, T Darrell. UAI 2012.
      <a href="assets/pdf/uai12_factorize.pdf">[PDF]</a>
      <!--<a href="wikipedia.html">[Dataset]</a> -->
    </p>
    <p class="abstract-text">
      We factorized the information contained in corresponding image and text with a novel HDP-based topic model that automatically learns both shared and private topics.
    </p>
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/nips11.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Heavy-tailed Distances for Gradient Based Image Descriptors</strong><br />
      Y Jia, T Darrell. NIPS 2011.
      <a href="assets/pdf/nips11_gcl.pdf">[PDF]</a>
      <a href="assets/pdf/nips11_gcl_supp.pdf">[Supplementary Material]</a>
      <a href="assets/pdf/nips11_gcl_poster.pdf">[Poster]</a>
    </p>
    <p class="abstract-text">
      We examined the heavy-tailed noise distribution of gradient-based image descriptors, and proposed a new distance metric that yields higher feature matching performances.
    </p>
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/iccv11.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Learning Cross-modality Similarity for Multinomial Data</strong><br />
      Y Jia, M Salzmann, T Darrell. ICCV 2011
      <a href="assets/pdf/iccv11_mm.pdf">[PDF]</a>
      <a href="assets/pdf/iccv11_mm_poster.pdf">[Poster]</a>
      <!--<a href="wikipedia.html">[Dataset]</a> -->
    </p>
    <p class="abstract-text">
      We propose a novel approach based on topic models and the Markov random field to capture the semantic relationships between documents from multiple modalities. 
    </p>
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/iccv11-b3do.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>A Category-level 3-D Database: Putting the Kinect to Work</strong><br />
      A Janoch, S Karayev, Y Jia, J Barron, M Fritz, K Saenko, T Darrell. ICCV-CDC4CV workshop 2011
      <a href="assets/pdf/iccv11_kinect.pdf">[PDF]</a>
      <a href="http://kinectdata.com/">[Dataset]</a>
    </p>
    <p class="abstract-text">
      We presented a dataset of color and depth image pairs collected from the Kinect sensor, gathered in real domestic and of?ce environments, for research on object-level recognition with multimodal sensor input.
    </p>
  </div>
</div>




<!--
 *** Software ***
-->
<h3>
	<a name='software'></a> Software 
</h3>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/mincepie.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>
      	<a href="https://github.com/Yangqing/mincepie">Mincepie: lightweighted Mapreduce</a>
      </strong>
    </p>
    <p class="abstract-text">
      A lightweighted mapreduce implementation purely written in Python. It's not the powerful yellow elephant, but is worth 30 minutes' learning time. Check <a href="https://gist.github.com/Yangqing/5596077" target="_blank">the script</a> that extracts gist features from all ImageNet images!
    </p>
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/decaf.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>
      	<a href="http://decaf.no-ip.org">Decaf</a>
      </strong>
    </p>
    <p class="abstract-text">
    Decaf is a general python framework for deep convolutional neural networks, relying on a set of scientific computation modules (such as numpy/scipy) to efficiently run CNN models without the need of a GPU. Decaf is still under development but an imagenet classification demo could be checked out <a href="http://decaf.berkeleyvision.org">here</a>.
    </p>
  </div>
</div>


<!--
 *** Teaching ***
-->
<h3>
	<a name='teaching'></a> Teaching (GSI)
</h3>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/cs188.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>
      	<a href="http://inst.eecs.berkeley.edu/~cs188/sp12/">CS188 Artificial Intelligence</a>
      </strong>, spring 2012.
    </p>
    <p class="abstract-text">
      Undergraduate AI course: search, CSP, games, MDP, Reinforcement Learning, Bayes' Nets, HMM, DBN, probabilistic inference, and a fun PacMan challenge.<br />
      Won the campus Outstanding GSI Award.
    </p>
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/cs281a.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>
      	<a href="http://inst.eecs.berkeley.edu/~cs281a/"> CS281a/Stat241a Statistical Learning Theory</a>
      </strong>, fall 2011.
    </p>
    <p class="abstract-text">
      Graduate level course: graphical models, probabilistic inference, parameter estimation, regression, exponential family, EM and HMM, factor analysis, Junction Tree Algorithm, Monte Carlo, Variational Inference, etc.
    </p>
  </div>
</div>

        </div>
      </div>
    </div>

    <!-- Footer
    ================================================== -->
    <hr>
    <footer class="footer">
    <div class="container">
      <div class="row">
        <div class="span12">
          <p>&copy; Yangqing Jia 2013</p>
        </div>
      </div>
    </div>
    </footer>



    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
<!--
    <script type="text/javascript" src="http://platform.twitter.com/widgets.js"></script>
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
    <script src="assets/js/bootstrap-transition.js"></script>
    <script src="assets/js/bootstrap-alert.js"></script>
    <script src="assets/js/bootstrap-modal.js"></script>
    <script src="assets/js/bootstrap-dropdown.js"></script>
    <script src="assets/js/bootstrap-scrollspy.js"></script>
    <script src="assets/js/bootstrap-tab.js"></script>
    <script src="assets/js/bootstrap-tooltip.js"></script>
    <script src="assets/js/bootstrap-popover.js"></script>
    <script src="assets/js/bootstrap-button.js"></script>
    <script src="assets/js/bootstrap-collapse.js"></script>
    <script src="assets/js/bootstrap-carousel.js"></script>
    <script src="assets/js/bootstrap-typeahead.js"></script>
    <script src="assets/js/bootstrap-affix.js"></script>
    <script src="assets/js/holder/holder.js"></script>
    <script src="assets/js/application.js"></script>
-->
  </body>
</html>
